{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud # 词云展示库\n",
    "from PIL import Image # 图像处理库\n",
    "import matplotlib.pyplot as plt # 图像展示库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAACL_2018_lines = []\n",
    "NAACL_2018_labels = []\n",
    "with open(\"./data/NAACL_2018_titles.txt\", 'r', encoding='utf-8') as inf:\n",
    "     for line in inf:\n",
    "        NAACL_2018_lines.append(line.strip(\"\\n\"))\n",
    "        NAACL_2018_labels.append(\"NAACL_2018\")\n",
    "        \n",
    "NAACL_2019_lines = []\n",
    "NAACL_2019_labels = []\n",
    "with open(\"./data/NAACL_2019_titles.txt\", 'r', encoding='utf-8') as inf:\n",
    "     for line in inf:\n",
    "        NAACL_2019_lines.append(line.strip(\"\\n\"))\n",
    "        NAACL_2019_labels.append(\"NAACL_2019\")\n",
    "        \n",
    "ACL_2018_lines = []\n",
    "ACL_2018_labels = []\n",
    "with open(\"./data/ACL_2018_titles.txt\", 'r', encoding='utf-8') as inf:\n",
    "     for line in inf:\n",
    "        ACL_2018_lines.append(line.strip(\"\\n\"))\n",
    "        ACL_2018_labels.append(\"ACL_2018\")\n",
    "        \n",
    "ACL_2019_lines = []\n",
    "ACL_2019_labels = []\n",
    "with open(\"./data/ACL_2019_titles.txt\", 'r', encoding='utf-8') as inf:\n",
    "     for line in inf:\n",
    "        ACL_2019_lines.append(line.strip(\"\\n\"))\n",
    "        ACL_2019_labels.append(\"ACL_2019\")\n",
    "        \n",
    "EMNLP_2018_lines = []\n",
    "EMNLP_2018_labels = []\n",
    "with open(\"./data/EMNLP_2018_titles.txt\", 'r', encoding='utf-8') as inf:\n",
    "     for line in inf:\n",
    "        EMNLP_2018_lines.append(line.strip(\"\\n\"))\n",
    "        EMNLP_2018_labels.append(\"EMNLP_2018\")\n",
    "        \n",
    "EMNLP_2019_lines = []\n",
    "EMNLP_2019_labels = []\n",
    "with open(\"./data/EMNLP_2019_titles.txt\", 'r', encoding='utf-8') as inf:\n",
    "     for line in inf:\n",
    "        EMNLP_2018_lines.append(line.strip(\"\\n\"))\n",
    "        EMNLP_2018_labels.append(\"EMNLP_2019\")\n",
    "        \n",
    "titles = EMNLP_2018_lines + EMNLP_2019_lines + ACL_2018_lines + ACL_2019_lines + NAACL_2018_lines + NAACL_2019_lines \n",
    "labels = EMNLP_2018_labels + EMNLP_2019_labels + ACL_2018_labels+ ACL_2019_labels + NAACL_2018_labels + NAACL_2019_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2501"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.文本挖掘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入停用词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = [line.strip() for line in open('stop_word_en.txt', encoding = \"utf-8\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'t\", \"'ve\", 'ZT', 'ZZ', 'a']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_en[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词、去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_cut = []\n",
    "for title in titles:\n",
    "    temp = title.split(\" \")\n",
    "    temp_st_word = []\n",
    "    for i in range(len(temp)):\n",
    "        temp_temp = temp[i].lower().strip(\" \").strip(\":\").strip(\"?\").strip(\"!\").strip(\",\").strip(\".\")\n",
    "        #temp_temp = lemmatizer(temp_temp)\n",
    "        if (temp_temp in stopwords_en) == False:\n",
    "            temp_st_word.append(temp_temp)\n",
    "    titles_cut.append(temp_st_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2501"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['proceedings',\n",
       "  '2018',\n",
       "  'conference',\n",
       "  'empirical',\n",
       "  'methods',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing'],\n",
       " ['privacy-preserving', 'neural', 'representations', 'text'],\n",
       " ['adversarial', 'removal', 'demographic', 'attributes', 'text', 'data'],\n",
       " ['declare',\n",
       "  'debunking',\n",
       "  'fake',\n",
       "  'news',\n",
       "  'false',\n",
       "  'claims',\n",
       "  'evidence-aware',\n",
       "  'deep',\n",
       "  'learning'],\n",
       " ['it’s', 'measuring', 'access', 'support', 'online', 'communities']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_cut[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_con_title_bag = []\n",
    "for i in range(len(titles_cut)):\n",
    "    for j in range(len(titles_cut[i])):\n",
    "        nlp_con_title_bag.append(titles_cut[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp_con_title_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('neural', 438), ('learn', 365), ('model', 358), ('gener', 279), ('languag', 239), ('network', 223), ('text', 194), ('translat', 186), ('word', 185), ('machin', 169), ('embed', 161), ('represent', 145), ('semant', 143), ('extract', 137), ('relat', 134), ('question', 123), ('knowledg', 121), ('classif', 109), ('attent', 106), ('pars', 103)]\n"
     ]
    }
   ],
   "source": [
    "word_counts = collections.Counter(nlp_con_title_bag)\n",
    "word_counts_top20 = word_counts.most_common(20)\n",
    "print(word_counts_top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = np.array(Image.open('pandaa.jpg')) # 定义词频背景\n",
    "wc = wordcloud.WordCloud(font_path='C:/Windows/Fonts/simhei.ttf',width=6400,\n",
    "                         prefer_horizontal=0.9, height=4000,\n",
    "                         mode='RGBA',background_color=None, max_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x266e30fcda0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.generate_from_frequencies(word_counts) # 从字典生成词云\n",
    "pic_name='result_count/EMNLP_1819_ACL_1819_NAACL_1819_TOP20_stem.png'\n",
    "wc.to_file(pic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('neural', 438), ('learn', 365), ('model', 358), ('gener', 279), ('languag', 239), ('network', 223), ('text', 194), ('translat', 186), ('word', 185), ('machin', 169), ('embed', 161), ('represent', 145), ('semant', 143), ('extract', 137), ('relat', 134), ('question', 123), ('knowledg', 121), ('classif', 109), ('attent', 106), ('pars', 103), ('detect', 102), ('graph', 102), ('entiti', 100), ('answer', 99), ('improv', 97), ('unsupervis', 93), ('predict', 89), ('sentenc', 88), ('evalu', 85), ('summar', 83), ('structur', 82), ('deep', 79), ('convers', 78), ('sentiment', 75), ('inform', 74), ('adversari', 73), ('natur', 70), ('read', 70), ('analysi', 69), ('dialogu', 68), ('label', 65), ('dataset', 64), ('cross-lingu', 64), ('transfer', 63), ('supervis', 63), ('domain', 63), ('comprehens', 62), ('adapt', 62), ('data', 60), ('sequenc', 59)]\n"
     ]
    }
   ],
   "source": [
    "#word_counts = collections.Counter(nlp_con_title_bag)\n",
    "word_counts_top50 = word_counts.most_common(50)\n",
    "print(word_counts_top50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = np.array(Image.open('pandaa.jpg')) # 定义词频背景\n",
    "wc = wordcloud.WordCloud(font_path='C:/Windows/Fonts/simhei.ttf',width=6400,\n",
    "                         prefer_horizontal=0.9, height=4000,\n",
    "                         mode='RGBA',background_color=None, max_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x26681211908>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.generate_from_frequencies(word_counts) # 从字典生成词云\n",
    "pic_name='result_count/EMNLP_1819_ACL_1819_NAACL_1819_TOP50_stem.png'\n",
    "wc.to_file(pic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('neural', 438), ('learning', 350), ('language', 208), ('text', 179), ('generation', 179), ('translation', 174), ('machine', 166), ('word', 165), ('models', 130), ('networks', 127), ('semantic', 126), ('knowledge', 120), ('model', 114), ('embeddings', 111), ('extraction', 111), ('classification', 109), ('modeling', 106), ('parsing', 102), ('question', 102), ('network', 96), ('representations', 93), ('unsupervised', 93), ('attention', 90), ('entity', 87), ('relation', 85), ('answering', 81), ('graph', 80), ('summarization', 80), ('deep', 79), ('detection', 77), ('sentiment', 75), ('adversarial', 72), ('sentence', 72), ('natural', 70), ('analysis', 69), ('reading', 67), ('cross-lingual', 63), ('data', 60), ('dialogue', 60), ('comprehension', 58), ('domain', 57), ('hierarchical', 57), ('improving', 56), ('transfer', 54), ('sequence', 54), ('evaluation', 53), ('approach', 53), ('representation', 52), ('dataset', 52), ('prediction', 52), ('context', 51), ('embedding', 50), ('recognition', 48), ('training', 48), ('dependency', 47), ('social', 46), ('joint', 46), ('reasoning', 44), ('inference', 43), ('multilingual', 42), ('multi-task', 41), ('latent', 41), ('framework', 40), ('based', 40), ('automatic', 40), ('adaptation', 39), ('visual', 39), ('multimodal', 38), ('chinese', 38), ('document', 38), ('labeling', 38), ('event', 37), ('media', 36), ('corpus', 36), ('understanding', 36), ('conversation', 36), ('dialog', 36), ('generating', 34), ('structure', 34), ('supervised', 34), ('languages', 31), ('end-to-end', 31), ('large-scale', 30), ('alignment', 30), ('relations', 30), ('evaluating', 30), ('selection', 30), ('role', 30), ('discourse', 29), ('induction', 29), ('generative', 29), ('memory', 29), ('', 29), ('supervision', 28), ('emotion', 28), ('response', 28), ('reinforcement', 28), ('abstractive', 28), ('study', 28), ('news', 27)]\n"
     ]
    }
   ],
   "source": [
    "word_counts_top100 = word_counts.most_common(100)\n",
    "print(word_counts_top100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = np.array(Image.open('pandaa.jpg')) # 定义词频背景\n",
    "wc = wordcloud.WordCloud(font_path='C:/Windows/Fonts/simhei.ttf',width=6400,\n",
    "                         prefer_horizontal=0.9, height=4000,\n",
    "                         mode='RGBA',background_color=None, max_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x173069c8630>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.generate_from_frequencies(word_counts) # 从字典生成词云\n",
    "pic_name='result_count/EMNLP_1819_ACL_1819_NAACL_1819_TOP100.png'\n",
    "wc.to_file(pic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.文本聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除停用词 去除标点 统一转为小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_key = []\n",
    "for title in titles:\n",
    "    temp = title.split(\" \")\n",
    "    temp_st_word = []\n",
    "    for i in range(len(temp)):\n",
    "        temp_temp = temp[i].lower().strip(\" \").strip(\":\").strip(\"?\").strip(\"!\").strip(\",\").strip(\".\")\n",
    "        if (temp_temp in stopwords_en) == False:\n",
    "            temp_st_word.append(temp_temp)\n",
    "    titles_key.append(temp_st_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['twowingos',\n",
       "  'two-wing',\n",
       "  'optimization',\n",
       "  'strategy',\n",
       "  'evidential',\n",
       "  'claim',\n",
       "  'verification'],\n",
       " ['associative',\n",
       "  'multichannel',\n",
       "  'autoencoder',\n",
       "  'multimodal',\n",
       "  'word',\n",
       "  'representation'],\n",
       " ['game-based', 'video-context', 'dialogue'],\n",
       " ['simnet',\n",
       "  'stepwise',\n",
       "  'image-topic',\n",
       "  'merging',\n",
       "  'network',\n",
       "  'generating',\n",
       "  'detailed',\n",
       "  'comprehensive',\n",
       "  'image',\n",
       "  'captions'],\n",
       " ['multimodal', 'language', 'analysis', 'recurrent', 'multistage', 'fusion']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_key[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_key_lines = []\n",
    "for title_key in titles_key:\n",
    "    temp = \" \".join(title_key)\n",
    "    titles_key_lines.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temporally grounding natural sentence video',\n",
       " 'preco large-scale dataset preschool vocabulary coreference resolution',\n",
       " 'adversarial transfer learning chinese named entity recognition self-attention mechanism',\n",
       " 'linguistic features improve generalization capability neural coreference resolvers',\n",
       " 'neural segmental hypergraphs overlapping mention recognition']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_key_lines[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键词抽取：Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_line_list = []\n",
    "extraction_title_list = []\n",
    "for i in range(len(titles_key_lines)):\n",
    "    if \"extraction\" in titles_key_lines[i]:\n",
    "        extraction_line_list.append(titles_key_lines[i])\n",
    "        extraction_title_list.append(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attention-Based Capsule Networks with Dynamic Routing for Relation Extraction',\n",
       " 'PubSE: A Hierarchical Model for Publication Extraction from Academic Homepages',\n",
       " 'Genre Separation Network with Adversarial Training for Cross-genre Relation Extraction',\n",
       " 'Temporal Information Extraction by Predicting Relative Time-lines',\n",
       " 'Jointly Multiple Events Extraction via Attention-based Graph Information Aggregation',\n",
       " 'RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information',\n",
       " 'Visual Supervision in Bootstrapped Information Extraction',\n",
       " 'Neural Relation Extraction via Inner-Sentence Noise Reduction and Transfer Learning',\n",
       " 'Graph Convolution over Pruned Dependency Trees Improves Relation Extraction',\n",
       " 'Multi-Level Structured Self-Attentions for Distantly Supervised Relation Extraction',\n",
       " 'N-ary Relation Extraction using Graph-State LSTM',\n",
       " 'Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention',\n",
       " 'Label-Free Distant Supervision for Relation Extraction via Knowledge Graph Embedding',\n",
       " 'Adversarial training for multi-context joint entity and relation extraction',\n",
       " 'Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and They Are Both Weakly Supervised',\n",
       " 'A Nil-Aware Answer Extraction Framework for Question Answering',\n",
       " 'Word Relation Autoencoder for Unseen Hypernym Extraction Using Word Embeddings',\n",
       " 'Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs',\n",
       " 'Coupling Global and Local Context for Unsupervised Aspect Extraction',\n",
       " 'Cross-lingual Structure Transfer for Relation and Event Extraction',\n",
       " 'Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial Event Extraction',\n",
       " 'Easy First Relation Extraction with Information Redundancy',\n",
       " 'Enhancing Local Feature Extraction with Global Representation for Neural Text Classification',\n",
       " 'Improving Distantly-Supervised Relation Extraction with Joint Label Embedding',\n",
       " 'Improving Relation Extraction with Knowledge-attention',\n",
       " 'Joint Event and Temporal Relation Extraction with Shared Representations and Structured Prediction',\n",
       " 'Learning the Extraction Order of Multiple Relational Facts in a Sentence with Reinforcement Learning',\n",
       " 'Leveraging 2-hop Distant Supervision from Table Entity Pairs for Relation Extraction',\n",
       " 'Leveraging Dependency Forest for Neural Medical Relation Extraction',\n",
       " 'Looking Beyond Label Noise: Shifted Label Distribution Matters in Distantly Supervised Relation Extraction',\n",
       " 'Multi-input Multi-output Sequence Labeling for Joint Extraction of Fact and Condition Tuples from Scientific Text',\n",
       " 'Nearly-Unsupervised Hashcode Representations for Biomedical Relation Extraction',\n",
       " 'Neural Cross-Lingual Relation Extraction Based on Bilingual Word Embedding Mapping',\n",
       " 'Open Domain Web Keyphrase Extraction Beyond Language Modeling',\n",
       " 'Open Event Extraction from Online Texts using a Generative Adversarial Network',\n",
       " 'Open Relation Extraction: Relational Knowledge Transfer from Supervised Data to Unsupervised Data',\n",
       " 'Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control',\n",
       " 'Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction',\n",
       " 'Supervising Unsupervised Open Information Extraction Models',\n",
       " 'Uncover Sexual Harassment Patterns from Personal Stories by Joint Key Element Extraction and Categorization',\n",
       " 'Weakly Supervised Multilingual Causality Extraction fromWikipedia',\n",
       " 'Context-Aware Neural Model for Temporal Information Extraction',\n",
       " 'Robust Distant Supervision Relation Extraction via Deep Reinforcement Learning',\n",
       " 'Adaptive Scaling for Sparse Detection in Information Extraction',\n",
       " 'Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension',\n",
       " 'Zero-Shot Transfer Learning for Event Extraction',\n",
       " 'Recursive Neural Structural Correspondence Network for Cross-domain Aspect and Opinion Co-Extraction',\n",
       " 'Document Modeling with External Attention for Sentence Extraction',\n",
       " 'TutorialBank: A Manually-Collected Corpus for Prerequisite Chains, Survey Extraction and Resource Recommendation',\n",
       " 'DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction',\n",
       " 'DOER: Dual Cross-Shared RNN for Aspect Term-Polarity Co-Extraction',\n",
       " 'Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision',\n",
       " 'Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction',\n",
       " 'Entity-Relation Extraction as Multi-Turn Question Answering',\n",
       " 'Exploiting Entity BIO Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data',\n",
       " 'Neural Relation Extraction for Knowledge Base Enrichment',\n",
       " 'DIAG-NRE: A Neural Pattern Diagnosis Framework for Distantly Supervised Neural Relation Extraction',\n",
       " 'Exploring Sequence-to-Sequence Learning in Aspect Term Extraction',\n",
       " 'Unsupervised Parallel Sentence Extraction with Parallel Segment Detection Helps Machine Translation',\n",
       " 'DocRED: A Large-Scale Document-Level Relation Extraction Dataset',\n",
       " 'Attention Guided Graph Convolutional Networks for Relation Extraction',\n",
       " 'Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification',\n",
       " 'GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction',\n",
       " 'Chinese Relation Extraction with Multi-Grained Information and External Linguistic Knowledge',\n",
       " 'Fine-Grained Temporal Relation Extraction',\n",
       " 'Exploring Pre-trained Language Models for Event Extraction and Generation',\n",
       " 'Open Domain Event Extraction Using Neural Latent Variable Models',\n",
       " 'Scaling Up Open Tagging from Tens to Thousands: Comprehension Empowered Attribute Value Extraction from Product Title',\n",
       " 'Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction',\n",
       " 'Unsupervised Information Extraction: Regularizing Discriminative Approaches with Relation Distribution Losses',\n",
       " 'Emotion-Cause Pair Extraction: A New Task to Emotion Analysis in Texts',\n",
       " 'Graph Neural Networks with Generated Parameters for Relation Extraction',\n",
       " 'ENCODING CONVERSATION CONTEXT FOR NEURAL KEYPHRASE EXTRACTION FROM MICROBLOG POSTS',\n",
       " 'FEVER: A LARGE-SCALE DATASET FOR FACT EXTRACTION AND VERIFICATION',\n",
       " 'GLOBAL RELATION EMBEDDING FOR RELATION EXTRACTION',\n",
       " 'IMPROVING TEMPORAL RELATION EXTRACTION WITH A GLOBALLY ACQUIRED STATISTICAL RESOURCE',\n",
       " 'JOINT BOOTSTRAPPING MACHINES FOR RELATION EXTRACTION',\n",
       " 'KEEP YOUR BEARINGS: LIGHTLY-SUPERVISED INFORMATION EXTRACTION WITH LADDER NETWORKS THAT AVOIDS SEMANTIC DRIFT',\n",
       " 'KEY2VEC: AUTOMATIC RANKED KEYPHRASE EXTRACTION FROM SCIENTIFIC ARTICLES USING PHRASE EMBEDDINGS',\n",
       " 'NEURAL STORYLINE EXTRACTION MODEL FOR STORYLINE GENERATION FROM NEWS ARTICLES',\n",
       " 'SEMI-SUPERVISED EVENT EXTRACTION WITH PARAPHRASE CLUSTERS',\n",
       " 'SIMULTANEOUSLY SELF-ATTENDING TO ALL MENTIONS FOR FULL-ABSTRACT BIOLOGICAL RELATION EXTRACTION',\n",
       " 'SUPERVISED OPEN INFORMATION EXTRACTION',\n",
       " 'SYNTACTIC PATTERNS IMPROVE INFORMATION EXTRACTION FOR MEDICAL SEARCH',\n",
       " 'SYNTACTICALLY AWARE NEURAL ARCHITECTURES FOR DEFINITION EXTRACTION',\n",
       " 'TEMPO-LEXICAL CONTEXT DRIVEN WORD EMBEDDING FOR CROSS-SESSION SEARCH TASK EXTRACTION',\n",
       " 'UNSUPERVISED KEYPHRASE EXTRACTION WITH MULTIPARTITE GRAPHS',\n",
       " 'VISUALLY GUIDED SPATIAL RELATION EXTRACTION FROM TEXT',\n",
       " 'A general framework for information extraction using dynamic span graphs',\n",
       " 'A Richer-but-Smarter Shortest Dependency Path with Attentive Augmentation for Relation Extraction',\n",
       " 'An Integrated Approach for Keyphrase Generation via Exploring the Power of Retrieval and Extraction',\n",
       " 'Biomedical Event Extraction based on Knowledge-driven Tree-LSTM',\n",
       " 'Combining Distant and Direct Supervision for Neural Relation Extraction',\n",
       " 'Connecting Language and Knowledge with Heterogeneous Representations for Neural Relation Extraction',\n",
       " 'Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions',\n",
       " 'Document-Level N-ary Relation Extraction with Multiscale Representation Learning',\n",
       " 'GAN Driven Semi-distant Supervision for Relation Extraction',\n",
       " 'Global Information in Local Convolution for Keyphrase Extraction',\n",
       " 'GraphIE: A Graph-Based Framework for Information Extraction',\n",
       " 'Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks',\n",
       " 'NLP Whack-A-Mole: Challenges in Cross-Domain Temporal Expression Extraction',\n",
       " 'Open Information Extraction from Question-Answer Pairs',\n",
       " 'OpenRM: Relation Mapping between Open Information Extraction and Knowledge Bases with Universal Schema',\n",
       " 'Predicting Annotation Difficulty to Improve Task Routing and Model Performance for Biomedical Information Extraction',\n",
       " 'Relation Extraction using Explicit Context Conditioning',\n",
       " 'Relation Extraction with Temporal Reasoning Based on Memory Augmented Distant Supervision',\n",
       " 'Sentence Embedding Alignment for Lifelong Relation Extraction',\n",
       " 'Structured Minimally Supervised Learning for Neural Relation Extraction',\n",
       " 'Target-oriented Opinion Words Extraction with Target-fused Neural Sequence Labeling',\n",
       " 'UHop: An Unrestricted-Hop Relation Extraction Framework for Knowledge-Based Question Answering',\n",
       " 'Unsupervised Extraction of Partial Translations for Neural Machine Translation',\n",
       " 'When Open Information Extraction Meets the Semi-Structured Web',\n",
       " 'Zero-Shot Cross-Lingual Opinion Target Extraction']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extraction_title_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键词抽取：Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_line_list = []\n",
    "unsupervised_title_list = []\n",
    "for i in range(len(titles_key_lines)):\n",
    "    if \"unsupervised\" in titles_key_lines[i]:\n",
    "        unsupervised_line_list.append(titles_key_lines[i])\n",
    "        unsupervised_title_list.append(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unsupervised Multilingual Word Embeddings',\n",
       " 'CLUSE: Cross-Lingual Unsupervised Sense Embeddings',\n",
       " 'Non-Adversarial Unsupervised Word Translation',\n",
       " 'Why is unsupervised alignment of English embeddings from different algorithms so hard?',\n",
       " 'Unsupervised Bilingual Lexicon Induction via Latent Variable Models',\n",
       " 'Learning Unsupervised Word Translations Without Adversaries',\n",
       " 'Auto-Dialabel: Labeling Dialogue Data with Unsupervised Learning',\n",
       " 'Supervised and Unsupervised Methods for Robust Separation of Section Titles and Prose Text in Web Documents',\n",
       " 'Improving Unsupervised Word-by-Word Translation with Language Model and Denoising Autoencoder',\n",
       " 'Unsupervised Learning of Syntactic Structure with Invertible Neural Projections',\n",
       " 'Heuristically Informed Unsupervised Idiom Usage Recognition',\n",
       " 'Unsupervised Cross-lingual Transfer of Word Embedding Spaces',\n",
       " 'Depth-bounding is effective: Improvements and evaluation of unsupervised PCFG induction',\n",
       " 'Unsupervised Statistical Machine Translation',\n",
       " 'Unsupervised Natural Language Generation with Denoising Autoencoders',\n",
       " 'Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement',\n",
       " 'Unsupervised Neural Word Segmentation for Chinese via Segmental Language Modeling',\n",
       " 'Phrase-Based & Neural Unsupervised Machine Translation',\n",
       " 'A Modular Architecture for Unsupervised Sarcasm Generation',\n",
       " 'Answers Unite! Unsupervised Metrics for Reinforced Summarization Models',\n",
       " 'Combining Unsupervised Pre-training and Annotator Rationales to Improve Low-shot Text Classification',\n",
       " 'Coupling Global and Local Context for Unsupervised Aspect Extraction',\n",
       " 'Do We Really Need Fully Unsupervised Cross-Lingual Embeddings?',\n",
       " 'Explicit Cross-lingual Pre-training for Unsupervised Machine Translation',\n",
       " 'Low-Resource Sequence Labeling via Unsupervised Multilingual Contextualized Representations',\n",
       " 'Multi-View Domain Adapted Sentence Embeddings for Low-Resource Unsupervised Duplicate Question Detection',\n",
       " 'Nearly-Unsupervised Hashcode Representations for Biomedical Relation Extraction',\n",
       " 'Open Relation Extraction: Relational Knowledge Transfer from Supervised Data to Unsupervised Data',\n",
       " 'Quick and (not so) Dirty: Unsupervised Selection of Justification Sentences for Multi-hop Question Answering',\n",
       " 'Specificity-Driven Cascading Approach for Unsupervised Sentiment Modification',\n",
       " 'Supervising Unsupervised Open Information Extraction Models',\n",
       " 'To Annotate or Not? Unsupervised Prediction of Performance Drop due to Domain Shift',\n",
       " 'Unsupervised Context Rewriting for Open Domain Conversation',\n",
       " 'Unsupervised Discovery of Multimodal Links in Multi-image, Multi-sentence Documents',\n",
       " 'Unsupervised Domain Adaptation for Political Document Analysis',\n",
       " 'Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling',\n",
       " 'Unsupervised Sentence Summarization using the Information Bottleneck Principle',\n",
       " 'Unsupervised Text Attribute Transfer via Iterative Matching and Translation',\n",
       " 'WikiCREM: A large unsupervised corpus for co-reference resolution',\n",
       " 'On the Limitations of Unsupervised Bilingual Dictionary Induction',\n",
       " 'A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings',\n",
       " 'Unsupervised Neural Machine Translation with Weight Sharing',\n",
       " 'Unsupervised Abstractive Meeting Summarization with Multi-Sentence Compression and Budgeted Submodular Maximization',\n",
       " 'Unsupervised Learning of Distributional Relation Vectors',\n",
       " 'Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation',\n",
       " 'Multi-Input Attention for Unsupervised OCR Correction',\n",
       " 'Task Refinement Learning for Improved Accuracy and Stability of Unsupervised Domain Adaptation',\n",
       " 'Towards Unsupervised Text Classification Leveraging Experts and Word Embeddings',\n",
       " 'Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking',\n",
       " 'Unsupervised Question Answering by Cloze Translation',\n",
       " 'Sentence Centrality Revisited for Unsupervised Summarization',\n",
       " 'Unsupervised Parallel Sentence Extraction with Parallel Segment Detection Helps Machine Translation',\n",
       " 'Unsupervised Bilingual Word Embedding Agreement for Unsupervised Neural Machine Translation',\n",
       " 'A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer',\n",
       " 'Self-Attentive, Multi-Context One-Class Classification for Unsupervised Anomaly Detection on Text',\n",
       " 'Unsupervised Neural Text Simplification',\n",
       " 'Unsupervised Multilingual Word Embedding with Limited Resources using Neural Language Models',\n",
       " 'Unsupervised Discovery of Gendered Language through Latent-Variable Modeling',\n",
       " 'Unsupervised Pivot Translation for Distant Languages',\n",
       " 'Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections',\n",
       " 'Unsupervised Learning of PCFGs with Normalizing Flow',\n",
       " 'Variance of average surprisal: a better predictor for quality of grammar from unsupervised PCFG induction',\n",
       " 'Unsupervised Information Extraction: Regularizing Discriminative Approaches with Relation Distribution Losses',\n",
       " 'Exploiting Invertible Decoders for Unsupervised Sentence Representation Learning',\n",
       " 'An Effective Approach to Unsupervised Machine Translation',\n",
       " 'Enhancing Unsupervised Generative Dependency Parser with Contextual Information',\n",
       " 'DEEPALIGNMENT: UNSUPERVISED ONTOLOGY MATCHING WITH REFINED WORD VECTORS',\n",
       " 'DISTRIBUTIONAL INCLUSION VECTOR EMBEDDING FOR UNSUPERVISED HYPERNYMY DETECTION',\n",
       " 'FROM PHONOLOGY TO SYNTAX: UNSUPERVISED LINGUISTIC TYPOLOGY AT DIFFERENT LEVELS WITH LANGUAGE EMBEDDINGS',\n",
       " 'SUPERVISED AND UNSUPERVISED TRANSFER LEARNING FOR QUESTION ANSWERING',\n",
       " 'UNSUPERVISED DISAMBIGUATION OF SYNCRETISM IN INFLECTED LEXICONS',\n",
       " 'UNSUPERVISED INDUCTION OF LINGUISTIC CATEGORIES WITH RECORDS OF READING, SPEAKING, AND WRITING',\n",
       " 'UNSUPERVISED KEYPHRASE EXTRACTION WITH MULTIPARTITE GRAPHS',\n",
       " 'UNSUPERVISED LEARNING OF SENTENCE EMBEDDINGS USING COMPOSITIONAL N-GRAM FEATURES',\n",
       " 'A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource Languages',\n",
       " 'Cross-topic distributional semantic representations via unsupervised mappings',\n",
       " 'Detecting Derogatory Compounds – An Unsupervised Approach',\n",
       " 'Extract and Edit: An Alternative to Back-Translation for Unsupervised Neural Machine Translation',\n",
       " 'How to Avoid Sentences Spelling Boring? Towards a Neural Approach to Unsupervised Metaphor Generation',\n",
       " 'Knowledge-Augmented Language Model and Its Application to Unsupervised Named-Entity Recognition',\n",
       " 'Learning Unsupervised Multilingual Word Embeddings with Incremental Multilingual Hubs',\n",
       " 'Low-Resource Syntactic Transfer with Unsupervised Source Reordering',\n",
       " 'Measuring the perceptual availability of phonological features during language acquisition using unsupervised binary stochastic autoencoders',\n",
       " 'Mining Discourse Markers for Unsupervised Sentence Representation Learning',\n",
       " 'Revisiting Adversarial Autoencoder for Unsupervised Word Translation with Cycle Consistency and Improved Training',\n",
       " 'Self-Discriminative Learning for Unsupervised Document Embedding',\n",
       " 'SEQ^3: Differentiable Sequence-to-Sequence-to-Sequence Autoencoder for Unsupervised Abstractive Sentence Compression',\n",
       " 'Simplified Neural Unsupervised Domain Adaptation',\n",
       " 'Unsupervised Deep Structured Semantic Models for Commonsense Reasoning',\n",
       " 'Unsupervised Dialog Structure Learning',\n",
       " 'Unsupervised Extraction of Partial Translations for Neural Machine Translation',\n",
       " 'Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders',\n",
       " 'Unsupervised Recurrent Neural Network Grammars']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsupervised_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unsupervised_title_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键词抽取：Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_line_list = []\n",
    "entity_title_list = []\n",
    "for i in range(len(titles_key_lines)):\n",
    "    if \"multi\" and \"domain\" in titles_key_lines[i]:\n",
    "        entity_line_list.append(titles_key_lines[i])\n",
    "        entity_title_list.append(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep Pivot-Based Modeling for Cross-language Cross-domain Transfer with Minimal Guidance',\n",
       " 'Multi-Domain Neural Machine Translation with Word-Level Domain Context Discrimination',\n",
       " 'Ranking Paragraphs for Improving Answer Recall in Open-Domain Question Answering',\n",
       " 'Modeling Temporality of Human Intentions by Domain Adaptation',\n",
       " 'Out-of-domain Detection based on Generative Adversarial Network',\n",
       " 'Supervised Domain Enablement Attention for Personalized Domain Classification',\n",
       " 'Adversarial Domain Adaptation for Duplicate Question Detection',\n",
       " 'A dataset and baselines for sequential open-domain question answering',\n",
       " 'Lessons from Natural Language Inference in the Clinical Domain',\n",
       " 'SyntaxSQLNet: Syntax Tree Networks for Complex and Cross-Domain Text-to-SQL Task',\n",
       " 'Neural Adaptation Layers for Cross-domain Named Entity Recognition',\n",
       " 'Learning Named Entity Tagger using Domain-Specific Dictionary',\n",
       " 'Logician and Orator: Learning from the Duality between Language and Knowledge in Open Domain',\n",
       " 'Transferring from Formal Newswire Domain with Hypernet for Twitter POS Tagging',\n",
       " 'Hierarchical Dirichlet Gaussian Marked Hawkes Process for Narrative Reconstruction in Continuous Time Domain',\n",
       " 'Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification',\n",
       " 'Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task',\n",
       " 'Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text',\n",
       " 'Multi-Source Domain Adaptation with Mixture of Experts',\n",
       " 'The BQ Corpus: A Large-scale Domain-specific Chinese Corpus For Sentence Semantic Equivalence Identification',\n",
       " 'Identifying Domain Adjacent Instances for Semantic Parsers',\n",
       " 'MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling',\n",
       " 'Adversarial Domain Adaptation for Machine Reading Comprehension',\n",
       " 'Answer-guided and Semantic Coherent Question Generation in Open-domain Conversation',\n",
       " 'Answering Complex Open-domain Questions Through Iterative Query Generation',\n",
       " 'Comparing and Developing Tools to Measure the Readability of Domain-Specific Texts',\n",
       " 'CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases',\n",
       " 'Detecting and Reducing Bias in a High Stakes Domain',\n",
       " 'Domain Adaptation for Person-Job Fit with Transferable Deep Global Match Network',\n",
       " 'Domain Adaptive Text Style Transfer',\n",
       " 'Domain-Invariant Feature Distillation for Cross-Domain Sentiment Classification',\n",
       " 'Editing-based SQL Query Generation for Cross-Domain Context-Dependent Questions',\n",
       " 'Fine-grained Knowledge Fusion for Sequence Labeling Domain Adaptation',\n",
       " 'Guided Dialog Policy Learning: Reward Estimation for Multi-Domain Task-Oriented Dialog',\n",
       " 'Improving Open-Domain Dialogue Systems via Multi-Turn Incomplete Utterance Restoration',\n",
       " 'Iterative Dual Domain Adaptation for Neural Machine Translation',\n",
       " 'Jupyter: A Large Scale Distantly Supervised Dataset for Open Domain Context Based Code Generation',\n",
       " 'Multi-View Domain Adapted Sentence Embeddings for Low-Resource Unsupervised Duplicate Question Detection',\n",
       " 'MultiDoGO: Multi-Domain Goal-Oriented Dialogues',\n",
       " 'MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims',\n",
       " 'Open Domain Web Keyphrase Extraction Beyond Language Modeling',\n",
       " 'PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text',\n",
       " 'Ranking and Sampling in Open-domain Question Answering',\n",
       " 'Shallow Domain Adaptive Embeddings for Sentiment Analysis',\n",
       " 'To Annotate or Not? Unsupervised Prediction of Performance Drop due to Domain Shift',\n",
       " 'Unsupervised Context Rewriting for Open Domain Conversation',\n",
       " 'Unsupervised Domain Adaptation for Political Document Analysis',\n",
       " 'Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling',\n",
       " 'YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension',\n",
       " 'Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples',\n",
       " 'Cross-Domain Sentiment Classification with Target Domain Specific Information',\n",
       " 'Strong Baselines for Neural Semi-Supervised Learning under Domain Shift',\n",
       " 'Identifying Transferable Information Across Domains for Cross-domain Sentiment Classification',\n",
       " 'Learning to Ask Questions in Open-domain Conversational Systems with Typed Decoders',\n",
       " 'Denoising Distantly Supervised Open-Domain Question Answering',\n",
       " 'Two Methods for Domain Adaptation of Bilingual Tasks: Delightfully Simple and Broadly Applicable',\n",
       " 'Domain Adaptation with Adversarial Training and Graph Embeddings',\n",
       " 'SemAxis: A Lightweight Framework to Characterize Domain-Specific Word Semantics Beyond Sentiment',\n",
       " 'Recursive Neural Structural Correspondence Network for Cross-domain Aspect and Opinion Co-Extraction',\n",
       " 'Learning Domain-Sensitive and Sentiment-Aware Word Embeddings',\n",
       " 'Efficient Large-Scale Neural Domain Classification with Personalized Attention',\n",
       " 'Reinforced Training Data Selection for Domain Adaptation',\n",
       " 'Semi-supervised Domain Adaptation for Dependency Parsing',\n",
       " 'Task Refinement Learning for Improved Accuracy and Stability of Unsupervised Domain Adaptation',\n",
       " 'Automatic Domain Adaptation Outperforms Manual Domain Adaptation for Predicting Financial Outcomes',\n",
       " 'Automatic Generation of High Quality CCGbanks for Parser Domain Adaptation',\n",
       " 'Neural Text Simplification of Clinical Letters with a Domain Specific Phrase Table',\n",
       " 'A Wind of Change: Detecting and Evaluating Lexical Semantic Change across Times and Domains',\n",
       " 'Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems',\n",
       " 'Multi-Hop Paragraph Retrieval for Open-Domain Question Answering',\n",
       " 'Analysis of Automatic Annotation Suggestions for Hard Discourse-Level Tasks in Expert Domains',\n",
       " 'XQA: A Cross-lingual Open-domain Question Answering Dataset',\n",
       " 'Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification',\n",
       " 'A Cross-Domain Transferable Neural Coherence Model',\n",
       " 'Latent Retrieval for Weakly Supervised Open Domain Question Answering',\n",
       " 'Open Domain Event Extraction Using Neural Latent Variable Models',\n",
       " 'Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset',\n",
       " 'Semi-supervised Stochastic Multi-Domain Learning using Variational Inference',\n",
       " 'Dynamically Composing Domain-Data Selection with Clean-Data Selection by ``Co-Curricular Learning\" for Neural Machine Translation',\n",
       " 'Neural Temporality Adaptation for Document Classification: Diachronic Word Embeddings and Domain Adaptation Models',\n",
       " 'SParC: Cross-Domain Semantic Parsing in Context',\n",
       " 'Domain Adaptive Dialog Generation via Meta Learning',\n",
       " 'Handling Domain Shift in Coreference Evaluation by Using Automatically Extracted Minimum Spans',\n",
       " 'Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation',\n",
       " 'Cross-Domain NER using Cross-Domain Language Modeling',\n",
       " 'Domain Adaptation of Neural Machine Translation by Lexicon Induction',\n",
       " 'Open-Domain Why-Question Answering with Adversarial Learning to Encode Answer Texts',\n",
       " 'Target-Guided Open-Domain Conversation',\n",
       " 'Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index (DenSPI)',\n",
       " 'A LAYPEOPLE STUDY ON TERMINOLOGY IDENTIFICATION ACROSS DOMAINS AND TASK DEFINITIONS',\n",
       " 'CROSS-DOMAIN REVIEW HELPFULNESS PREDICTION BASED ON CONVOLUTIONAL NEURAL NETWORKS WITH AUXILIARY DOMAIN DISCRIMINATORS',\n",
       " 'FEUDAL REINFORCEMENT LEARNING FOR DIALOGUE MANAGEMENT IN LARGE DOMAINS',\n",
       " 'LEARNING DOMAIN REPRESENTATION FOR MULTI-DOMAIN SENTIMENT CLASSIFICATION',\n",
       " 'LSDSCC: A LARGE SCALE DOMAIN-SPECIFIC CONVERSATIONAL CORPUS FOR RESPONSE GENERATION WITH DIVERSITY ORIENTED EVALUATION METRICS',\n",
       " 'MITTENS: AN EXTENSION OF GLOVE FOR LEARNING DOMAIN-SPECIALIZED REPRESENTATIONS',\n",
       " 'MULTINOMIAL ADVERSARIAL NETWORKS FOR MULTI-DOMAIN TEXT CLASSIFICATION',\n",
       " 'PIVOT BASED LANGUAGE MODELING FOR IMPROVED NEURAL DOMAIN ADAPTATION',\n",
       " 'WHAT’S IN A DOMAIN? LEARNING DOMAIN-ROBUST TEXT REPRESENTATIONS USING ADVERSARIAL TRAINING',\n",
       " 'Adversarial Category Alignment Network for Cross-domain Sentiment Classification',\n",
       " 'Continuous Learning for Large-scale Personalized Domain Classification',\n",
       " 'Curriculum Learning for Domain Adaptation in Neural Machine Translation',\n",
       " 'Domain adaptation for part-of-speech tagging of noisy user-generated text',\n",
       " 'Improving Cross-Domain Chinese Word Segmentation with Word Embeddings',\n",
       " 'Improving Domain Adaptation Translation with Shared Encoder-Decoder',\n",
       " 'Joint Learning of Pre-Trained and Random Units for Domain Adaptation in Part-of-Speech Tagging',\n",
       " 'Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering',\n",
       " 'Multilingual prediction of Alzheimer’s disease through domain adaptation and concept-based language modelling',\n",
       " 'NLP Whack-A-Mole: Challenges in Cross-Domain Temporal Expression Extraction',\n",
       " 'Overcoming Catastrophic Forgetting During Domain Adaptation of Neural Machine Translation',\n",
       " 'Simplified Neural Unsupervised Domain Adaptation']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_title_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将文本中的词语转换为词频矩阵 矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "vectorizer = CountVectorizer()\n",
    "#该类会统计每个词语的tf-idf权值\n",
    "transformer = TfidfTransformer()\n",
    "#第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(titles_key_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_k_choice(train_vecs, start_k, end_k):\n",
    "    SSE = []\n",
    "    SSE_d1 = [] #sse的一阶导数\n",
    "    SSE_d2 = [] #sse的二阶导数\n",
    "    models = [] #保存每次的模型\n",
    "    for i in range(start_k, end_k):\n",
    "        kmeans_model = KMeans(n_clusters=i)\n",
    "        kmeans_model.fit(train_vecs)\n",
    "        SSE.append(kmeans_model.inertia_)  # 保存每一个k值的SSE值\n",
    "        models.append(kmeans_model)\n",
    "    # 求二阶导数，通过sse方法计算最佳k值\n",
    "    SSE_length = len(SSE)\n",
    "    for i in range(1, SSE_length):\n",
    "        SSE_d1.append((SSE[i - 1] - SSE[i]) / 2)\n",
    "    for i in range(1, len(SSE_d1) - 1):\n",
    "        SSE_d2.append((SSE_d1[i - 1] - SSE_d1[i]) / 2)\n",
    "\n",
    "    best_model = models[SSE_d2.index(max(SSE_d2)) + 1]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_k_choice(tfidf, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=14, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = vectorizer.get_feature_names()\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "cluster_label_list_5=[]\n",
    "for i in range(14):\n",
    "    clusters_temp=[]\n",
    "    for ind in order_centroids[i, :5]:\n",
    "        clusters_temp.append(word[ind])\n",
    "    cluster_label_list_5.append(clusters_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = vectorizer.get_feature_names()\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "cluster_label_list_3=[]\n",
    "for i in range(14):\n",
    "    clusters_temp=[]\n",
    "    for ind in order_centroids[i, :5]:\n",
    "        clusters_temp.append(word[ind])\n",
    "    cluster_label_list_3.append(clusters_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = vectorizer.get_feature_names()\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "cluster_label_list_10=[]\n",
    "for i in range(14):\n",
    "    clusters_temp=[]\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        clusters_temp.append(word[ind])\n",
    "    cluster_label_list_10.append(clusters_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = pd.DataFrame()\n",
    "df_titles[\"Title\"] = titles\n",
    "df_titles[\"Confer\"] = labels\n",
    "df_titles[\"Non_stopword\"] = titles_key_lines \n",
    "df_titles[\"Cluster_Label\"] = model.labels_\n",
    "#df_titles[\"Cluster_Keyword\"] = cluster_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = list(df_titles[\"Cluster_Label\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Confer</th>\n",
       "      <th>Non_stopword</th>\n",
       "      <th>Cluster_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Proceedings of the 2018 Conference on Empirica...</td>\n",
       "      <td>EMNLP_2018</td>\n",
       "      <td>proceedings 2018 conference empirical methods ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Privacy-preserving Neural Representations of Text</td>\n",
       "      <td>EMNLP_2018</td>\n",
       "      <td>privacy-preserving neural representations text</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adversarial Removal of Demographic Attributes ...</td>\n",
       "      <td>EMNLP_2018</td>\n",
       "      <td>adversarial removal demographic attributes tex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeClarE: Debunking Fake News and False Claims ...</td>\n",
       "      <td>EMNLP_2018</td>\n",
       "      <td>declare debunking fake news false claims evide...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s going to be okay: Measuring Access to Sup...</td>\n",
       "      <td>EMNLP_2018</td>\n",
       "      <td>it’s measuring access support online communities</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title      Confer  \\\n",
       "0  Proceedings of the 2018 Conference on Empirica...  EMNLP_2018   \n",
       "1  Privacy-preserving Neural Representations of Text  EMNLP_2018   \n",
       "2  Adversarial Removal of Demographic Attributes ...  EMNLP_2018   \n",
       "3  DeClarE: Debunking Fake News and False Claims ...  EMNLP_2018   \n",
       "4  It’s going to be okay: Measuring Access to Sup...  EMNLP_2018   \n",
       "\n",
       "                                        Non_stopword  Cluster_Label  \n",
       "0  proceedings 2018 conference empirical methods ...              6  \n",
       "1     privacy-preserving neural representations text              2  \n",
       "2  adversarial removal demographic attributes tex...              0  \n",
       "3  declare debunking fake news false claims evide...              1  \n",
       "4   it’s measuring access support online communities              0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label_list_10_line = [\" \".join(x) for x in cluster_label_list_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['semantic parsing text attention detection modeling models model based social',\n",
       " 'learning summarization multi task abstractive document text deep sentence neural',\n",
       " 'neural network models networks detection attention parsing based modeling deep',\n",
       " 'generation text neural response to dialogue learning keyphrase based sequence',\n",
       " 'cross lingual transfer embeddings word parsing unsupervised learning semantic dependency',\n",
       " 'reading comprehension machine multi reasoning hop answer passage questions style',\n",
       " 'language natural models inference neural modeling model understanding learning generation',\n",
       " 'word embeddings representations embedding sense unsupervised contextualized segmentation vectors based',\n",
       " 'question answering answer domain open knowledge generation multi hop learning',\n",
       " 'extraction relation entity named recognition supervised linking learning grained supervision',\n",
       " 'translation machine neural attention adaptation context learning unsupervised word improving',\n",
       " 'end to dialogue oriented systems networks dialog speech learning aspect',\n",
       " 'knowledge graph embedding graphs reasoning based completion learning networks prediction',\n",
       " 'classification sentiment text aspect analysis multi networks attention domain label']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_label_list_10_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic</td>\n",
       "      <td>parsing</td>\n",
       "      <td>text</td>\n",
       "      <td>attention</td>\n",
       "      <td>detection</td>\n",
       "      <td>modeling</td>\n",
       "      <td>models</td>\n",
       "      <td>model</td>\n",
       "      <td>based</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning</td>\n",
       "      <td>summarization</td>\n",
       "      <td>multi</td>\n",
       "      <td>task</td>\n",
       "      <td>abstractive</td>\n",
       "      <td>document</td>\n",
       "      <td>text</td>\n",
       "      <td>deep</td>\n",
       "      <td>sentence</td>\n",
       "      <td>neural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neural</td>\n",
       "      <td>network</td>\n",
       "      <td>models</td>\n",
       "      <td>networks</td>\n",
       "      <td>detection</td>\n",
       "      <td>attention</td>\n",
       "      <td>parsing</td>\n",
       "      <td>based</td>\n",
       "      <td>modeling</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generation</td>\n",
       "      <td>text</td>\n",
       "      <td>neural</td>\n",
       "      <td>response</td>\n",
       "      <td>to</td>\n",
       "      <td>dialogue</td>\n",
       "      <td>learning</td>\n",
       "      <td>keyphrase</td>\n",
       "      <td>based</td>\n",
       "      <td>sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cross</td>\n",
       "      <td>lingual</td>\n",
       "      <td>transfer</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>word</td>\n",
       "      <td>parsing</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>learning</td>\n",
       "      <td>semantic</td>\n",
       "      <td>dependency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0              1         2           3            4          5  \\\n",
       "0    semantic        parsing      text   attention    detection   modeling   \n",
       "1    learning  summarization     multi        task  abstractive   document   \n",
       "2      neural        network    models    networks    detection  attention   \n",
       "3  generation           text    neural    response           to   dialogue   \n",
       "4       cross        lingual  transfer  embeddings         word    parsing   \n",
       "\n",
       "              6          7         8           9  \n",
       "0        models      model     based      social  \n",
       "1          text       deep  sentence      neural  \n",
       "2       parsing      based  modeling        deep  \n",
       "3      learning  keyphrase     based    sequence  \n",
       "4  unsupervised   learning  semantic  dependency  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_key_wordcluster_label_list_10 = pd.DataFrame(cluster_label_list_10)\n",
    "df_key_wordcluster_label_list_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_key_wordcluster_label_list_10.to_csv(\"ACL_NAACL_EMNLP_2018_2019_tittle_cluster_centers_14_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translation machine neural adaptation learning attention unsupervised context word improving'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(cluster_label_list_10[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_cluster_keys = []\n",
    "for i in range(len(titles_key_lines)):\n",
    "    key_temp_list = []\n",
    "    cluster_keywords_candidate = cluster_label_list_10[model_labels[i]]\n",
    "    for key_temp in cluster_keywords_candidate:\n",
    "        if key_temp in titles_key_lines[i]:\n",
    "            key_temp_list.append(key_temp)\n",
    "    line_cluster_keys.append(\" \".join(key_temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', 'multi']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_cluster_keys[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles[\"Cluster_Keyword\"] = line_cluster_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = df_titles.sort_values(by = \"Cluster_Label\", axis = 0, ascending = True)\n",
    "df_titles = df_titles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Confer</th>\n",
       "      <th>Non_stopword</th>\n",
       "      <th>Cluster_Label</th>\n",
       "      <th>Cluster_Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NAACL_2019</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Query-focused Scenario Construction</td>\n",
       "      <td>EMNLP_2019</td>\n",
       "      <td>query-focused scenario construction</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RELEVANT EMOTION RANKING FROM TEXT CONSTRAINED...</td>\n",
       "      <td>NAACL_2018</td>\n",
       "      <td>relevant emotion ranking text constrained emot...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recommendation as a Communication Game: Self-S...</td>\n",
       "      <td>EMNLP_2019</td>\n",
       "      <td>recommendation communication game self-supervi...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recursive Context-Aware Lexical Simplification</td>\n",
       "      <td>EMNLP_2019</td>\n",
       "      <td>recursive context-aware lexical simplification</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title      Confer  \\\n",
       "0                                                     NAACL_2019   \n",
       "1                Query-focused Scenario Construction  EMNLP_2019   \n",
       "2  RELEVANT EMOTION RANKING FROM TEXT CONSTRAINED...  NAACL_2018   \n",
       "3  Recommendation as a Communication Game: Self-S...  EMNLP_2019   \n",
       "4     Recursive Context-Aware Lexical Simplification  EMNLP_2019   \n",
       "\n",
       "                                        Non_stopword  Cluster_Label  \\\n",
       "0                                                                 0   \n",
       "1                query-focused scenario construction              0   \n",
       "2  relevant emotion ranking text constrained emot...              0   \n",
       "3  recommendation communication game self-supervi...              0   \n",
       "4     recursive context-aware lexical simplification              0   \n",
       "\n",
       "  Cluster_Keyword  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.to_csv(\"ACL_NAACL_EMNLP_2018_2019_tittle_cluster_14_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
